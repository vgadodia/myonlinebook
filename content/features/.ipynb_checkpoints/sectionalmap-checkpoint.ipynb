{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reformat NetCDF4 File for Function Call ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install netCDF4\n",
    "!{sys.executable} -m pip install xarray\n",
    "import opedia\n",
    "import netCDF4\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import datetime as dt\n",
    "from scipy.interpolate import griddata\n",
    "import db\n",
    "import subset\n",
    "import common as com\n",
    "import climatology as clim\n",
    "from bokeh.io import output_notebook\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.layouts import column\n",
    "from bokeh.palettes import all_palettes\n",
    "from bokeh.models import HoverTool, LinearColorMapper, BasicTicker, ColorBar\n",
    "from bokeh.embed import components\n",
    "import jupyterInline as jup\n",
    "if jup.jupytered():\n",
    "    from tqdm import tqdm_notebook as tqdm\n",
    "else:\n",
    "    from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Function ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sectionMap(tables, variabels, dt1, dt2, lat1, lat2, lon1, lon2, depth1, depth2, fname, exportDataFlag):\n",
    "    data, lats, lons, subs, frameVars, units = [], [], [], [], [], []\n",
    "    xs, ys, zs = [], [], []\n",
    "    for i in tqdm(range(len(tables)), desc='overall'):\n",
    "        if not db.hasField(tables[i], 'depth'):\n",
    "            continue        \n",
    "        df = subset.section(tables[i], variabels[i], dt1, dt2, lat1, lat2, lon1, lon2, depth1, depth2)\n",
    "        if len(df) < 1:\n",
    "            com.printTQDM('%d: No matching entry found: Table: %s, Variable: %s ' % (i+1, tables[i], variabels[i]), err=True )\n",
    "            continue\n",
    "        com.printTQDM('%d: %s retrieved (%s).' % (i+1, variabels[i], tables[i]), err=False)\n",
    "\n",
    "        ############### export retrieved data ###############\n",
    "        if exportDataFlag:      # export data\n",
    "            dirPath = 'data/'\n",
    "            if not os.path.exists(dirPath):\n",
    "                os.makedirs(dirPath)                \n",
    "            exportData(df, path=dirPath + fname + '_' + tables[i] + '_' + variabels[i] + '.csv')\n",
    "        #####################################################\n",
    "\n",
    "        times = df[df.columns[0]].unique()\n",
    "        lats = df.lat.unique()\n",
    "        lons = df.lon.unique()\n",
    "        depths = df.depth.unique()\n",
    "        shape = (len(lats), len(lons), len(depths))\n",
    "\n",
    "        hours =  [None]\n",
    "        if 'hour' in df.columns:\n",
    "            hours = df.hour.unique()\n",
    "\n",
    "        unit = com.getUnit(tables[i], variabels[i])\n",
    "\n",
    "        for t in times:\n",
    "            for h in hours:\n",
    "                frame = df[df[df.columns[0]] == t]\n",
    "                sub = variabels[i] + unit + ', ' + df.columns[0] + ': ' + str(t) \n",
    "                if h != None:\n",
    "                    frame = frame[frame['hour'] == h]\n",
    "                    sub = sub + ', hour: ' + str(h) + 'hr'\n",
    "                try:    \n",
    "                    shot = frame[variabels[i]].values.reshape(shape)\n",
    "                except Exception as e:\n",
    "                    continue    \n",
    "                data.append(shot)\n",
    "                \n",
    "                xs.append(lons)\n",
    "                ys.append(lats)\n",
    "                zs.append(depths)\n",
    "\n",
    "                frameVars.append(variabels[i])\n",
    "                units.append(unit)\n",
    "                subs.append(sub)\n",
    "                \n",
    "    bokehSec(data=data, subject=subs, fname=fname, ys=ys, xs=xs, zs=zs, units=units, variabels=frameVars)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NetCDF Compatible Function ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xarraySectionMap(tables, variabels, dt1, dt2, lat1, lat2, lon1, lon2, depth1, depth2, fname, exportDataFlag):\n",
    "    data, lats, lons, subs, frameVars, units = [], [], [], [], [], []\n",
    "    xs, ys, zs = [], [], []\n",
    "    for i in tqdm(range(len(tables)), desc='overall'):\n",
    "        \n",
    "        toDateTime = tables[i].indexes['TIME'].to_datetimeindex()\n",
    "        tables[i]['TIME'] = toDateTime\n",
    "        table = tables[i].sel(TIME = slice(dt1, dt2), LAT_C = slice(lat1, lat2), LON_C = slice(lon1, lon2), DEP_C = slice(depth1, depth2))\n",
    "        ############### export retrieved data ###############\n",
    "        if exportDataFlag:      # export data\n",
    "            dirPath = 'data/'\n",
    "            if not os.path.exists(dirPath):\n",
    "                os.makedirs(dirPath)                \n",
    "            exportData(df, path=dirPath + fname + '_' + tables[i] + '_' + variabels[i] + '.csv')\n",
    "        #####################################################\n",
    "\n",
    "        times = np.unique(table.variables['TIME'].values)\n",
    "        lats = np.unique(table.variables['LAT_C'].values)\n",
    "        lons = np.unique(table.variables['LON_C'].values)\n",
    "        depths = np.flip(np.unique(table.variables['DEP_C'].values))\n",
    "        shape = (len(lats), len(lons), len(depths))\n",
    "        \n",
    "        hours = [None]\n",
    "\n",
    "        unit = '[PLACEHOLDER]'\n",
    "\n",
    "        for t in times:\n",
    "            for h in hours:\n",
    "                frame = table.sel(TIME = t, method = 'nearest')\n",
    "                sub = variabels[i] + unit + ', TIME: ' + str(t) \n",
    "                if h != None:\n",
    "                    frame = frame[frame['hour'] == h]\n",
    "                    sub = sub + ', hour: ' + str(h) + 'hr'\n",
    "                try:    \n",
    "                    shot = frame[variabels[i]].values.reshape(shape)\n",
    "                    shot[shot < 0] = float('NaN')\n",
    "                except Exception as e:\n",
    "                    continue    \n",
    "                data.append(shot)\n",
    "                \n",
    "                xs.append(lons)\n",
    "                ys.append(lats)\n",
    "                zs.append(depths)\n",
    "\n",
    "                frameVars.append(variabels[i])\n",
    "                units.append(unit)\n",
    "                subs.append(sub)\n",
    "    \n",
    "    bokehSec(data=data, subject=subs, fname=fname, ys=ys, xs=xs, zs=zs, units=units, variabels=frameVars)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bokehSec(data, subject, fname, ys, xs, zs, units, variabels):\n",
    "    TOOLS=\"crosshair,pan,wheel_zoom,zoom_in,zoom_out,box_zoom,undo,redo,reset,tap,save,box_select,poly_select,lasso_select,\"\n",
    "    w = 1000\n",
    "    h = 500\n",
    "    p = []\n",
    "    data_org = list(data)\n",
    "    for ind in range(len(data_org)):\n",
    "        data = data_org[ind]\n",
    "        lon = xs[ind]\n",
    "        lat = ys[ind]\n",
    "        depth = zs[ind]      \n",
    "        \n",
    "        bounds = (None, None)\n",
    "        paletteName = com.getPalette(variabels[ind], 10)\n",
    "        low, high = bounds[0], bounds[1]\n",
    "        \n",
    "        if low == None:\n",
    "            low, high = np.nanmin(data[ind].flatten()), np.nanmax(data[ind].flatten())\n",
    "        color_mapper = LinearColorMapper(palette=paletteName, low=low, high=high)\n",
    "        output_notebook()\n",
    "        if len(lon) > len(lat):\n",
    "            p1 = figure(tools=TOOLS, toolbar_location=\"above\", title=subject[ind], plot_width=w, plot_height=h, x_range=(np.min(lon), np.max(lon)), y_range=(-np.max(depth), -np.min(depth)))\n",
    "            data = np.nanmean(data, axis=0)\n",
    "            data = np.transpose(data)\n",
    "            data = np.squeeze(data)\n",
    "            xLabel = 'Longitude'\n",
    "            data = regulate(lat, lon, depth, data)\n",
    "            p1.image(image=[data], color_mapper=color_mapper, x=np.min(lon), y=-np.max(depth), dw=np.max(lon)-np.min(lon), dh=np.max(depth)-np.min(depth))\n",
    "        else:\n",
    "            p1 = figure(tools=TOOLS, toolbar_location=\"above\", title=subject[ind], plot_width=w, plot_height=h, x_range=(np.min(lat), np.max(lat)), y_range=(-np.max(depth), -np.min(depth)))\n",
    "            data = np.nanmean(data, axis=1)\n",
    "            data = np.transpose(data)\n",
    "            data = np.squeeze(data)\n",
    "            xLabel = 'Latitude'      \n",
    "            data = regulate(lat, lon, depth, data)\n",
    "            p1.image(image=[data], color_mapper=color_mapper, x=np.min(lat), y=-np.max(depth), dw=np.max(lat)-np.min(lat), dh=np.max(depth)-np.min(depth))\n",
    "\n",
    "        p1.xaxis.axis_label = xLabel\n",
    "        p1.add_tools(HoverTool(\n",
    "            tooltips=[\n",
    "                (xLabel.lower(), '$x'),\n",
    "                ('depth', '$y'),\n",
    "                (variabels[ind]+units[ind], '@image'),\n",
    "            ],\n",
    "            mode='mouse'\n",
    "        ))\n",
    "\n",
    "        p1.yaxis.axis_label = 'depth [m]'\n",
    "        color_bar = ColorBar(color_mapper=color_mapper, ticker=BasicTicker(),\n",
    "                        label_standoff=12, border_line_color=None, location=(0,0))\n",
    "        p1.add_layout(color_bar, 'right')\n",
    "        p.append(p1)\n",
    "    dirPath = 'embed/'\n",
    "   # if not os.path.exists(dirPath):\n",
    "   #     os.makedirs(dirPath)        \n",
    "   # if not inline:      ## if jupyter is not the caller\n",
    "   # output_file(dirPath + fname + \".html\", title=\"Section Map\")\n",
    "    show(column(p))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regulate(lat, lon, depth, data):\n",
    "    depth = -1* depth \n",
    "    deltaZ = np.min( np.abs( depth - np.roll(depth, -1) ) )\n",
    "    newDepth =  np.arange(np.min(depth), np.max(depth), deltaZ)        \n",
    "\n",
    "    if len(lon) > len(lat):\n",
    "        lon1, depth1 = np.meshgrid(lon, depth)\n",
    "        lon2, depth2 = np.meshgrid(lon, newDepth)\n",
    "        lon1 = lon1.ravel()\n",
    "        lon1 = list(lon1[lon1 != np.isnan])\n",
    "        depth1 = depth1.ravel()\n",
    "        depth1 = list(depth1[depth1 != np.isnan])\n",
    "        data = data.ravel()\n",
    "        data = list(data[data != np.isnan])\n",
    "        data = griddata((lon1, depth1), data, (lon2, depth2), method='linear')\n",
    "    else:   \n",
    "        lat1, depth1 = np.meshgrid(lat, depth)\n",
    "        lat2, depth2 = np.meshgrid(lat, newDepth)\n",
    "        lat1 = lat1.ravel()\n",
    "        lat1 = list(lat1[lat1 != np.isnan])\n",
    "        depth1 = depth1.ravel()\n",
    "        depth1 = list(depth1[depth1 != np.isnan])\n",
    "        data = data.ravel()\n",
    "        data = list(data[data != np.isnan])\n",
    "        data = griddata((lat1, depth1), data, (lat2, depth2), method='linear')\n",
    "\n",
    "    depth = -1* depth \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Space ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTS NETCDF-COMPATIBLE FUNCTION\n",
    "xFile = xr.open_dataset('http://3.88.71.225:80/thredds/dodsC/las/id-a1d60eba44/data_usr_local_tomcat_content_cbiomes_20190510_20_darwin_v0.2_cs510_darwin_v0.2_cs510_nutrients.nc.jnl')\n",
    "\n",
    "tables = [xFile]    # see catalog.csv  for the complete list of tables and variable names\n",
    "variabels = ['O2']                            # see catalog.csv  for the complete list of tables and variable name\n",
    "dt1 = '2016-04-22'   # PISCES is a weekly model, and here we are using monthly climatology of Darwin model\n",
    "dt2 = '2016-04-22'\n",
    "lat1, lat2 = 23, 55\n",
    "lon1, lon2 = -159, -157\n",
    "depth1, depth2 = 0, 3597\n",
    "fname = 'sectional'\n",
    "exportDataFlag = False       # True if you you want to download data\n",
    "\n",
    "xarraySectionMap(tables, variabels, dt1, dt2, lat1, lat2, lon1, lon2, depth1, depth2, fname, exportDataFlag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
